import os
import requests
import chromadb
from openai import OpenAI

# --- å‡†å¤‡å·¥ä½œ (ç¯å¢ƒå˜é‡è¯»å–) ---
SILICONFLOW_API_KEY = os.environ.get("SILICONFLOW_API_KEY")
if not SILICONFLOW_API_KEY:
    print("é”™è¯¯ï¼šæœªèƒ½åœ¨ç³»ç»Ÿç¯å¢ƒå˜é‡ä¸­æ‰¾åˆ° 'SILICONFLOW_API_KEY'ã€‚")
    exit()

project_root = os.path.dirname(os.path.abspath(__file__))

# --- æ ¸å¿ƒå‡½æ•° (get_embedding ä¿æŒä¸å˜) ---
def get_embedding(text_chunk):
    # ... (æ­¤å‡½æ•°å†…å®¹ä¸ä¹‹å‰å®Œå…¨ç›¸åŒï¼Œä¸ºèŠ‚çœç¯‡å¹…æ­¤å¤„çœç•¥) ...
    url = "https://api.siliconflow.cn/v1/embeddings"
    model_name = "BAAI/bge-m3"
    headers = { "Authorization": f"Bearer {SILICONFLOW_API_KEY}", "Content-Type": "application/json" }
    payload = { "model": model_name, "input": text_chunk }
    try:
        response = requests.post(url, json=payload, headers=headers)
        if response.status_code == 200:
            return response.json()['data'][0]['embedding']
        else:
            return None
    except Exception as e:
        return None

# --- âœ¨âœ¨âœ¨ æœ€ç»ˆç‰ˆæµå¼ç”Ÿæˆå‡½æ•°ï¼ˆä¿æŒä¸å˜ï¼‰ âœ¨âœ¨âœ¨ ---
def generate_answer_stream_with_reasoning(query, retrieved_chunks):
    client = OpenAI(api_key=SILICONFLOW_API_KEY, base_url="https://api.siliconflow.cn/v1")
    context = "\n\n---\n\n".join(retrieved_chunks)
    prompt = f"""
è¯·ä½ æ‰®æ¼”ä¸€ä¸ªã€Šå°¼å°”ï¼šæœºæ¢°çºªå…ƒã€‹çš„èµ„æ·±ä¸“å®¶ã€‚
ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ä¸‹é¢æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç®€æ´ã€æ¸…æ™°åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
åœ¨å›ç­”å‰ï¼Œè¯·å…ˆè¿›è¡Œä¸€æ­¥æ€è€ƒï¼ˆReasoningï¼‰ï¼Œåˆ†æä¸Šä¸‹æ–‡ä¸­çš„å“ªäº›ä¿¡æ¯å¯ä»¥ç”¨æ¥å›ç­”é—®é¢˜ã€‚
ç„¶åï¼Œæ ¹æ®ä½ çš„æ€è€ƒï¼Œç»™å‡ºæœ€ç»ˆçš„ç­”æ¡ˆã€‚
ã€ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‘:
{context}
ã€ç”¨æˆ·çš„é—®é¢˜ã€‘:
{query}
"""
    model_name = "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B" 
    try:
        stream = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": prompt}],
            stream=True
        )
        return stream
    except Exception as e:
        print(f"ç”Ÿæˆç­”æ¡ˆè¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        return None

# --- ä¸»ç¨‹åºå…¥å£ (æœ€ç»ˆå¢å¼ºç‰ˆï¼Œå¸¦çŠ¶æ€ç®¡ç†ï¼) ---
if __name__ == "__main__":
    db_path = os.path.join(project_root, "nier_vector_db")
    client = chromadb.PersistentClient(path=db_path)
    collection_name = "nier_automata_kb"
    collection = client.get_or_create_collection(name=collection_name)

    if collection.count() == 0:
        print("æ•°æ®åº“ä¸ºç©ºï¼Œè¯·å…ˆè¿è¡Œä¸€æ¬¡å¸¦æœ‰åˆå§‹åŒ–åŠŸèƒ½çš„è„šæœ¬æ¥å¡«å……æ•°æ®ã€‚")
        exit()
    else:
        print(f"æ•°æ®åº“ '{collection_name}' ä¸­å·²å­˜åœ¨ {collection.count()} ä¸ªçŸ¥è¯†å—ã€‚")

    query_text = "æ¸¸æˆæœ‰å“ªäº›ç»“å±€ï¼Ÿ"
    print("\n" + "="*30)
    print(f"ç”¨æˆ·é—®é¢˜: {query_text}")
    
    query_vector = get_embedding(query_text)
    
    if query_vector:
        results = collection.query(
            query_embeddings=[query_vector],
            n_results=3
        )
        retrieved_documents = results['documents'][0]
        
        print("\næ£€ç´¢åˆ°çš„ç›¸å…³ä¿¡æ¯:")
        for i, doc in enumerate(retrieved_documents):
            print(f"  - [ç‰‡æ®µ{i+1}]: {doc[:80]}...")
            
        stream = generate_answer_stream_with_reasoning(query_text, retrieved_documents)
        
        if stream:
            print("\n" + "="*30)
            
            # âœ¨âœ¨âœ¨ å¼•å…¥çŠ¶æ€ç®¡ç†ï¼Œæ¸…æ™°åˆ†å‰²æ€è€ƒä¸å›ç­” âœ¨âœ¨âœ¨
            # current_phase å¯ä»¥æ˜¯ None, 'reasoning', æˆ– 'answering'
            current_phase = None

            for chunk in stream:
                if not chunk.choices:
                    continue
                
                delta = chunk.choices[0].delta

                # æ•è·å¹¶æ‰“å°æ¨ç†å†…å®¹
                if delta.reasoning_content:
                    # å¦‚æœè¿™æ˜¯æ€è€ƒçš„ç¬¬ä¸€ä¸ªæ•°æ®å—
                    if current_phase != 'reasoning':
                        current_phase = 'reasoning'
                        print("ğŸ¤” AIæ­£åœ¨æ€è€ƒ...")
                    print(delta.reasoning_content, end="", flush=True)
                
                # æ•è·å¹¶æ‰“å°æœ€ç»ˆå›ç­”å†…å®¹
                elif delta.content:
                    # å¦‚æœè¿™æ˜¯å›ç­”çš„ç¬¬ä¸€ä¸ªæ•°æ®å—
                    if current_phase != 'answering':
                        # å¦‚æœä¹‹å‰æ˜¯åœ¨æ€è€ƒï¼Œå°±æ‰“å°ä¸€ä¸ªåˆ†å‰²çº¿ï¼Œè®©æ ¼å¼æ›´æ¸…æ™°
                        if current_phase == 'reasoning':
                            print("\n" + "-"*20)
                        current_phase = 'answering'
                        print("ğŸ¤– å°¼å°”AIä¸‡äº‹é€šçš„å›ç­”:")
                    print(delta.content, end="", flush=True)
            
            print() # ç»“æŸæ—¶æ¢è¡Œ
            
    else:
        print("é—®é¢˜å‘é‡åŒ–å¤±è´¥ï¼Œæ— æ³•è¿›è¡ŒæŸ¥è¯¢ã€‚")